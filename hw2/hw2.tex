\documentclass{ctexart}
\usepackage{amsmath,bm}
\usepackage{setspace}
\usepackage{xeCJK}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsfonts,amssymb}
\usepackage[a4paper,scale=0.8]{geometry}
\usepackage{hyperref}
\usepackage{pythonhighlight}
\usepackage{float}
\usepackage{amsthm}
\renewcommand\tablename{Table}
\newenvironment{solution}{\begin{proof}[\indent\bf Solution]}{\end{proof}}
\renewcommand{\proofname}{\indent\bf Proof}
\setCJKmainfont{华光书宋_CNKI}
\newCJKfontfamily\kaiti{华光楷体_CNKI}
\newCJKfontfamily\hei{华光黑体_CNKI}
\newCJKfontfamily\fsong{华光仿宋_CNKI}
\newfontfamily\code{Courier New}
\linespread{1.5} \setlength\parindent{2 em}
\title{\Huge 中国科学技术大学计算机学院\\《数据隐私的方法伦理和实践》作业}
\date{\LARGE 2021.06.06}
\begin{document}
\begin{hei}  \maketitle\end{hei}
\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.4]{USTC.png}

\end{figure}
\begin{LARGE}\begin{align*}
         & \text{学生姓名：\underline{胡毅翔}}     \\
         & \text{学生学号：\underline{PB18000290}}\end{align*}\end{LARGE}
\par
\par\par
\centerline{\large 计算机实验教学中心制}
\par \centerline {\large 2019年9月}
\newpage
\section{\hei Concept of DP}
\subsection{\hei}
Prove that the Laplace mechanism preserves ($\epsilon$, 0)-DP.
\par
\begin{proof} Let $x \in \mathbb{N}^{|\mathcal{X}|}$ and $y \in \mathbb{N}^{|\mathcal{X}|}$ be such that $\|x-y\|_{1} \leq 1$, and let $f(\cdot)$ be some function $f: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathbb{R}^{k}$. Let $p_{x}$ denote the probability density function of $\mathcal{M}_{L}(x, f, \varepsilon)$, and let $p_{y}$ denote the probability density function of $\mathcal{M}_{L}(y, f, \varepsilon)$. We compare the two at some arbitrary point $z \in \mathbb{R}^{k}$
    $$
        \begin{aligned}
            \frac{p_{x}(z)}{p_{y}(z)} & =\prod_{i=1}^{k}\left(\frac{\exp \left(-\frac{\varepsilon\left|f(x)_{i}-z_{i}\right|}{\Delta f}\right)}{\exp \left(-\frac{\varepsilon\left|f(y)_{i}-z_{i}\right|}{\Delta f}\right)}\right) \\
                                      & =\prod_{i=1}^{k} \exp \left(\frac{\varepsilon\left(\left|f(y)_{i}-z_{i}\right|-\left|f(x)_{i}-z_{i}\right|\right)}{\Delta f}\right)                                                        \\
                                      & \leq \prod_{i=1}^{k} \exp \left(\frac{\varepsilon\left|f(x)_{i}-f(y)_{i}\right|}{\Delta f}\right)                                                                                          \\
                                      & =\exp \left(\frac{\varepsilon \cdot\|f(x)-f(y)\|_{1}}{\Delta f}\right)                                                                                                                     \\
                                      & \leq \exp (\varepsilon)
        \end{aligned}
    $$
    where the first inequality follows from the triangle inequality, and the last follows from the definition of sensitivity and the fact that $\|x-y\|_{1} \leq 1$. That $\frac{p_{x}(z)}{p_{y}(z)} \geq \exp (-\varepsilon)$ follows by symmetry.
\end{proof}
\subsection{}
Please explain the difference between $(\epsilon, 0)-\mathrm{DP}$ and $(\epsilon, \delta)$ -DP. Typically, what range of $\delta$ we're interested in? Explain the reason.
\par
\begin{solution}
    Even $\delta$ is negligible, there are theoretical distinctions between $(\varepsilon, 0)$ - and $(\varepsilon, \delta)$ - differential privacy.
    \par $(\varepsilon, 0)$ -differential privacy: for every run of the mechanism $M(x)$, the output observed is (almost) equally likely to be observed on every neighboring database, simultaneously.
    \par $(\varepsilon, \delta)$ - differential privacy: given an output $\xi \sim M(x)$ it may be possible to find a database $y$ such that $\xi$ is much more likely to be produced on $y$ than it is when the database is $x$.
    The privacy loss (divergence) incurred by observation $\xi$ :
    $$
        \mathcal{L}_{\mathcal{M}(x) \| \mathcal{M}(y)}^{(\xi)}=\ln \left(\frac{\operatorname{Pr}[\mathcal{M}(x)=\xi]}{\operatorname{Pr}[\mathcal{M}(y)=\xi]}\right)
    $$
    \par $(\varepsilon, \delta)$ - differential privacy ensures that for all adjacent $x, y$, the absolute value of the privacy loss will be bounded by $\varepsilon$ with probability at least $1-\delta$.
    \par
    Typically, we are interested in values of $\delta$ that are less than the inverse
    of any polynomial in the size of the database.
    \par
    Because, for each piece of data in data set, there is a probability that it will be released. Each piece of different data in this ralease is independent,
    so this mechanism can release $n\delta$ sample. So in order to prevent such leakage, it must be less than $1/n$.

\end{solution}
\subsection{}
Please explain the difference between DP and Local DP.
\begin{solution}
    Definition of $\epsilon$ -local differential privacy is that a randomized function $f$ satisfies $\epsilon$ local differential privacy if and only if for
    any two input tuples $t$ and $t^{\prime}$ in the domain of $f$, and for any output $t^{*}$ of $f$, we have:
    $$
        \operatorname{Pr}\left[f(t)=t^{*}\right] \leq \exp (\epsilon) \cdot \operatorname{Pr}\left[f\left(t^{\prime}\right)=t^{*}\right]
    $$
    \begin{enumerate}
        \item The notation $\operatorname{Pr}[\cdot]$ means probability. If $f$ 's output is continuous, $\operatorname{Pr}[\cdot]$ is replaced by the probability density function.
        \item  Basically, local differential privacy is a special case of differential privacy where the random perturbation is performed by the users, not by the aggregator.
        \item  According to the above definition, the aggregator, who receives the perturbed tuple $t$, cannot distinguish whether the true tuple is $t$ or another tuple $t^{\prime}$ with high confidence (controlled by parameter $\left.\epsilon\right)$, regardless of the background information of the aggregator.
        \item This provides plausible deniability to the user.
    \end{enumerate}
    While the definition of differential privacy is that A randomized algorithm $M$ with domain $\mathbb{N}^{|X|}$ is $(\epsilon, \delta)$ -differentially private if for all $S \subset$ Range $(M)$ and for all $x, y \in \mathbb{N}|X|$ such that $\|x-y\|_{1} \leq 1$ :
    $$
        \operatorname{Pr}[M(x) \in S] \leq \exp (\epsilon) \operatorname{Pr}[M(y) \in S]+\delta
    $$
    where the probability space is over the coin flips of the mechanism $M$. If $\delta=0$, we say that $M$ is $\delta$ -differentially private.
    \par We can find out the difference between LDP and DP is that
    DP restrictions on tuple $x, y \in \mathbb{N}|X|$ such that $\|x-y\|_{1} \leq 1$, while LDP restrictions on any two input tuples $t$ and $t^{\prime}$.

\end{solution}
\section{Basics of DP}
\begin{table}[H]\label{1}
    \begin{tabular}{llllllll}\text { ID } & \text { Sex }       & \text { Chinese } & \text { Mathematics } & \text { English } &
        \text { Physics }      & \text { Chemistry } & \text { Biology }                                               \\ 1 & \text { Male } & 96 & 58 & 80 & 53 & 56 & 100
        \\ 2 & \text { Male } & 60 & 63 & 77 & 50 & 59 & 75 \\ 3 & \text { Female } & 83 & 86 & 98 & 69 & 80 & 100 \\ \ldots & & & & & & &
        \\ 2000 & \text { Female } & 86 & 83 & 98 & 87 & 82 & 92\end{tabular}\caption{Scores of students in School A}
\end{table}

Table 1 is the database records scores of students in School A in the final exam. We need to help teacher query the database while protecting the privacy of students' scores. The domain of this database is
$\{$ Male, Female $\} \times\{0,1,2, \ldots, 100\}^{6} .$
In this question, assume that two inputs $X$ and $Y$ are neighbouring inputs if $X$ can be obtained from
$Y$ by removing or adding one element. Answer the following questions.
\subsection{}
What is the sensitivity of the following queries:
\begin{enumerate}\item $q_{1}=\frac{1}{2000} \sum_{I D=1}^{2000}$ Mathematics $_{I D}$
    \item $q_{2}=\max _{I D \in[1,2000]}$ English $_{I D}$
\end{enumerate}
\subsection{}
Design $\epsilon$ -differential privacy mechanisms corresponding to the two queries in $2.1$ where $\epsilon=0.1 .$ (Using Laplace mechanism for $q_{1}$, Exponential mechanism for $q_{2} .$ )
\subsection{}
Let $M_{1}, M_{2}, \ldots, M_{100}$ be 100 Gaussian mechanisms that satisfy $\left(\epsilon_{0}, \delta_{0}\right)-\mathrm{DP}$, respectively, with respect to the database. Given $(\epsilon, \delta)=\left(1.25,10^{-5}\right)$, calculate $\sigma$ for every query with the composition theorem (Theorem $3.16$ in the textbook) and the advanced composition theorem (Theorem $3.20$ in the textbook, choose $\delta^{\prime}=\delta$ ) such that the total query satisfies $(\epsilon, \delta)$ - DP.
\end{document}